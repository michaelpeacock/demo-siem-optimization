CREATE STREAM SPLUNK (
  event VARCHAR,
  time BIGINT,
  host VARCHAR,
  source VARCHAR,
  sourcetype VARCHAR,
  index VARCHAR
) WITH (
  KAFKA_TOPIC='splunk-s2s-events', VALUE_FORMAT='JSON');

CREATE STREAM CISCO_ASA AS
    SELECT * FROM SPLUNK
    WHERE sourcetype = 'cisco:asa'
    EMIT CHANGES;




CREATE STREAM CISCO_ASA_FILTER_106023
WITH (KAFKA_TOPIC='CISCO_ASA_FILTER_106023', PARTITIONS=1, VALUE_FORMAT='AVRO')
AS SELECT
    SPLUNK.event,
    SPLUNK.source,
    SPLUNK.sourcetype,
    SPLUNK.index
FROM SPLUNK SPLUNK
WHERE ((SPLUNK.sourcetype = 'cisco:asa') AND (NOT (SPLUNK.event LIKE '%ASA-4-106023%')))
EMIT CHANGES;




CREATE STREAM FIREWALLS (
    `src` VARCHAR,
    `messageID` BIGINT,
    `index` VARCHAR,
    `dest` VARCHAR,
    `hostname` VARCHAR,
    `protocol` VARCHAR,
    `action` VARCHAR,
    `srcport` BIGINT,
    `sourcetype` VARCHAR,
    `destport` BIGINT,
    `location` VARCHAR,
    `timestamp` VARCHAR
) WITH (
KAFKA_TOPIC='firewalls', value_format='JSON'
);

CREATE TABLE AGGREGATOR WITH (KAFKA_TOPIC='AGGREGATOR', KEY_FORMAT='JSON', PARTITIONS=1, REPLICAS=1) AS SELECT
    `hostname`,
    `messageID`,
    `action`,
    `src`,
    `dest`,
    `destport`,
    `sourcetype`,
    as_value(`hostname`) as hostname,
    as_value(`messageID`) as messageID,
    as_value(`action`) as action,
    as_value(`src`) as src,
    as_value(`dest`) as dest,
    as_value(`destport`) as dest_port,
    as_value(`sourcetype`) as sourcetype,
    TIMESTAMPTOSTRING(WINDOWSTART, 'yyyy-MM-dd HH:mm:ss', 'UTC') TIMESTAMP,
    60 DURATION,
    COUNT(*) COUNTS
FROM FIREWALLS FIREWALLS
WINDOW TUMBLING ( SIZE 60 SECONDS )
GROUP BY `sourcetype`, `action`, `hostname`, `messageID`, `src`, `dest`, `destport`
EMIT CHANGES;





index=* sourcetype=httpevent
| bin span=5m _time
| stats sum(COUNTS) as raw_events count(_raw) as filtered_events by _time, SOURCETYPE, HOSTNAME, MESSAGEID, , ACTION, SRC, DEST, DEST_PORT, DURATION
| eval savings=round(((raw_events-filtered_events)/raw_events) * 100,2) . "%"
| sort -savings



